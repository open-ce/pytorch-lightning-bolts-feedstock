From 5413954d490633e05df212d14c99a684881b4ba4 Mon Sep 17 00:00:00 2001
From: Deepali Chourasia <deepch23@in.ibm.com>
Date: Tue, 1 Aug 2023 06:25:55 +0000
Subject: [PATCH] remove moco mocel support

---
 pyproject.toml                                |   4 -
 .../models/self_supervised/__init__.py        |   2 -
 .../models/self_supervised/moco/LICENSE       | 399 ------------------
 .../models/self_supervised/moco/__init__.py   |   8 -
 .../models/self_supervised/moco/callbacks.py  |  29 --
 .../self_supervised/moco/moco2_module.py      | 399 ------------------
 tests/models/self_supervised/test_models.py   |  15 +-
 tests/models/test_scripts.py                  |   5 -
 tests/transforms/test_transforms.py           |   8 -
 9 files changed, 1 insertion(+), 868 deletions(-)
 delete mode 100644 src/pl_bolts/models/self_supervised/moco/LICENSE
 delete mode 100644 src/pl_bolts/models/self_supervised/moco/__init__.py
 delete mode 100644 src/pl_bolts/models/self_supervised/moco/callbacks.py
 delete mode 100644 src/pl_bolts/models/self_supervised/moco/moco2_module.py

diff --git a/pyproject.toml b/pyproject.toml
index 2f34e45..ee1dcee 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -197,9 +197,6 @@ module = [
     "pl_bolts.models.self_supervised.cpc.networks",
     "pl_bolts.models.self_supervised.cpc.transforms",
     "pl_bolts.models.self_supervised.evaluator",
-    "pl_bolts.models.self_supervised.moco.callbacks",
-    "pl_bolts.models.self_supervised.moco.moco2_module",
-    "pl_bolts.models.self_supervised.moco.transforms",
     "pl_bolts.models.self_supervised.resnets",
     "pl_bolts.models.self_supervised.simclr.simclr_finetuner",
     "pl_bolts.models.self_supervised.simclr.simclr_module",
@@ -218,7 +215,6 @@ module = [
     "pl_bolts.optimizers.lars",
     "pl_bolts.optimizers.lr_scheduler",
     "pl_bolts.transforms.dataset_normalizations",
-    "pl_bolts.transforms.self_supervised.moco_transforms",
     "pl_bolts.transforms.self_supervised.simclr_transforms",
     "pl_bolts.transforms.self_supervised.ssl_transforms",
     "pl_bolts.transforms.self_supervised.swav_transforms",
diff --git a/src/pl_bolts/models/self_supervised/__init__.py b/src/pl_bolts/models/self_supervised/__init__.py
index c2518bb..9b13b89 100644
--- a/src/pl_bolts/models/self_supervised/__init__.py
+++ b/src/pl_bolts/models/self_supervised/__init__.py
@@ -20,7 +20,6 @@ from pl_bolts.models.self_supervised.amdim.amdim_module import AMDIM
 from pl_bolts.models.self_supervised.byol.byol_module import BYOL
 from pl_bolts.models.self_supervised.cpc.cpc_module import CPC_v2
 from pl_bolts.models.self_supervised.evaluator import SSLEvaluator
-from pl_bolts.models.self_supervised.moco.moco2_module import Moco_v2
 from pl_bolts.models.self_supervised.simclr.simclr_module import SimCLR
 from pl_bolts.models.self_supervised.simsiam.simsiam_module import SimSiam
 from pl_bolts.models.self_supervised.ssl_finetuner import SSLFineTuner
@@ -31,7 +30,6 @@ __all__ = [
     "BYOL",
     "CPC_v2",
     "SSLEvaluator",
-    "Moco_v2",
     "SimCLR",
     "SimSiam",
     "SSLFineTuner",
diff --git a/src/pl_bolts/models/self_supervised/moco/LICENSE b/src/pl_bolts/models/self_supervised/moco/LICENSE
deleted file mode 100644
index 6b28d56..0000000
--- a/src/pl_bolts/models/self_supervised/moco/LICENSE
+++ /dev/null
@@ -1,399 +0,0 @@
-Attribution-NonCommercial 4.0 International
-
-=======================================================================
-
-Creative Commons Corporation ("Creative Commons") is not a law firm and
-does not provide legal services or legal advice. Distribution of
-Creative Commons public licenses does not create a lawyer-client or
-other relationship. Creative Commons makes its licenses and related
-information available on an "as-is" basis. Creative Commons gives no
-warranties regarding its licenses, any material licensed under their
-terms and conditions, or any related information. Creative Commons
-disclaims all liability for damages resulting from their use to the
-fullest extent possible.
-
-Using Creative Commons Public Licenses
-
-Creative Commons public licenses provide a standard set of terms and
-conditions that creators and other rights holders may use to share
-original works of authorship and other material subject to copyright
-and certain other rights specified in the public license below. The
-following considerations are for informational purposes only, are not
-exhaustive, and do not form part of our licenses.
-
-     Considerations for licensors: Our public licenses are
-     intended for use by those authorized to give the public
-     permission to use material in ways otherwise restricted by
-     copyright and certain other rights. Our licenses are
-     irrevocable. Licensors should read and understand the terms
-     and conditions of the license they choose before applying it.
-     Licensors should also secure all rights necessary before
-     applying our licenses so that the public can reuse the
-     material as expected. Licensors should clearly mark any
-     material not subject to the license. This includes other CC-
-     licensed material, or material used under an exception or
-     limitation to copyright. More considerations for licensors:
-	wiki.creativecommons.org/Considerations_for_licensors
-
-     Considerations for the public: By using one of our public
-     licenses, a licensor grants the public permission to use the
-     licensed material under specified terms and conditions. If
-     the licensor's permission is not necessary for any reason--for
-     example, because of any applicable exception or limitation to
-     copyright--then that use is not regulated by the license. Our
-     licenses grant only permissions under copyright and certain
-     other rights that a licensor has authority to grant. Use of
-     the licensed material may still be restricted for other
-     reasons, including because others have copyright or other
-     rights in the material. A licensor may make special requests,
-     such as asking that all changes be marked or described.
-     Although not required by our licenses, you are encouraged to
-     respect those requests where reasonable. More_considerations
-     for the public:
-	wiki.creativecommons.org/Considerations_for_licensees
-
-=======================================================================
-
-Creative Commons Attribution-NonCommercial 4.0 International Public
-License
-
-By exercising the Licensed Rights (defined below), You accept and agree
-to be bound by the terms and conditions of this Creative Commons
-Attribution-NonCommercial 4.0 International Public License ("Public
-License"). To the extent this Public License may be interpreted as a
-contract, You are granted the Licensed Rights in consideration of Your
-acceptance of these terms and conditions, and the Licensor grants You
-such rights in consideration of benefits the Licensor receives from
-making the Licensed Material available under these terms and
-conditions.
-
-Section 1 -- Definitions.
-
-  a. Adapted Material means material subject to Copyright and Similar
-     Rights that is derived from or based upon the Licensed Material
-     and in which the Licensed Material is translated, altered,
-     arranged, transformed, or otherwise modified in a manner requiring
-     permission under the Copyright and Similar Rights held by the
-     Licensor. For purposes of this Public License, where the Licensed
-     Material is a musical work, performance, or sound recording,
-     Adapted Material is always produced where the Licensed Material is
-     synched in timed relation with a moving image.
-
-  b. Adapter's License means the license You apply to Your Copyright
-     and Similar Rights in Your contributions to Adapted Material in
-     accordance with the terms and conditions of this Public License.
-
-  c. Copyright and Similar Rights means copyright and/or similar rights
-     closely related to copyright including, without limitation,
-     performance, broadcast, sound recording, and Sui Generis Database
-     Rights, without regard to how the rights are labeled or
-     categorized. For purposes of this Public License, the rights
-     specified in Section 2(b)(1)-(2) are not Copyright and Similar
-     Rights.
-  d. Effective Technological Measures means those measures that, in the
-     absence of proper authority, may not be circumvented under laws
-     fulfilling obligations under Article 11 of the WIPO Copyright
-     Treaty adopted on December 20, 1996, and/or similar international
-     agreements.
-
-  e. Exceptions and Limitations means fair use, fair dealing, and/or
-     any other exception or limitation to Copyright and Similar Rights
-     that applies to Your use of the Licensed Material.
-
-  f. Licensed Material means the artistic or literary work, database,
-     or other material to which the Licensor applied this Public
-     License.
-
-  g. Licensed Rights means the rights granted to You subject to the
-     terms and conditions of this Public License, which are limited to
-     all Copyright and Similar Rights that apply to Your use of the
-     Licensed Material and that the Licensor has authority to license.
-
-  h. Licensor means the individual(s) or entity(ies) granting rights
-     under this Public License.
-
-  i. NonCommercial means not primarily intended for or directed towards
-     commercial advantage or monetary compensation. For purposes of
-     this Public License, the exchange of the Licensed Material for
-     other material subject to Copyright and Similar Rights by digital
-     file-sharing or similar means is NonCommercial provided there is
-     no payment of monetary compensation in connection with the
-     exchange.
-
-  j. Share means to provide material to the public by any means or
-     process that requires permission under the Licensed Rights, such
-     as reproduction, public display, public performance, distribution,
-     dissemination, communication, or importation, and to make material
-     available to the public including in ways that members of the
-     public may access the material from a place and at a time
-     individually chosen by them.
-
-  k. Sui Generis Database Rights means rights other than copyright
-     resulting from Directive 96/9/EC of the European Parliament and of
-     the Council of 11 March 1996 on the legal protection of databases,
-     as amended and/or succeeded, as well as other essentially
-     equivalent rights anywhere in the world.
-
-  l. You means the individual or entity exercising the Licensed Rights
-     under this Public License. Your has a corresponding meaning.
-
-Section 2 -- Scope.
-
-  a. License grant.
-
-       1. Subject to the terms and conditions of this Public License,
-          the Licensor hereby grants You a worldwide, royalty-free,
-          non-sublicensable, non-exclusive, irrevocable license to
-          exercise the Licensed Rights in the Licensed Material to:
-
-            a. reproduce and Share the Licensed Material, in whole or
-               in part, for NonCommercial purposes only; and
-
-            b. produce, reproduce, and Share Adapted Material for
-               NonCommercial purposes only.
-
-       2. Exceptions and Limitations. For the avoidance of doubt, where
-          Exceptions and Limitations apply to Your use, this Public
-          License does not apply, and You do not need to comply with
-          its terms and conditions.
-
-       3. Term. The term of this Public License is specified in Section
-          6(a).
-
-       4. Media and formats; technical modifications allowed. The
-          Licensor authorizes You to exercise the Licensed Rights in
-          all media and formats whether now known or hereafter created,
-          and to make technical modifications necessary to do so. The
-          Licensor waives and/or agrees not to assert any right or
-          authority to forbid You from making technical modifications
-          necessary to exercise the Licensed Rights, including
-          technical modifications necessary to circumvent Effective
-          Technological Measures. For purposes of this Public License,
-          simply making modifications authorized by this Section 2(a)
-          (4) never produces Adapted Material.
-
-       5. Downstream recipients.
-
-            a. Offer from the Licensor -- Licensed Material. Every
-               recipient of the Licensed Material automatically
-               receives an offer from the Licensor to exercise the
-               Licensed Rights under the terms and conditions of this
-               Public License.
-
-            b. No downstream restrictions. You may not offer or impose
-               any additional or different terms or conditions on, or
-               apply any Effective Technological Measures to, the
-               Licensed Material if doing so restricts exercise of the
-               Licensed Rights by any recipient of the Licensed
-               Material.
-
-       6. No endorsement. Nothing in this Public License constitutes or
-          may be construed as permission to assert or imply that You
-          are, or that Your use of the Licensed Material is, connected
-          with, or sponsored, endorsed, or granted official status by,
-          the Licensor or others designated to receive attribution as
-          provided in Section 3(a)(1)(A)(i).
-
-  b. Other rights.
-
-       1. Moral rights, such as the right of integrity, are not
-          licensed under this Public License, nor are publicity,
-          privacy, and/or other similar personality rights; however, to
-          the extent possible, the Licensor waives and/or agrees not to
-          assert any such rights held by the Licensor to the limited
-          extent necessary to allow You to exercise the Licensed
-          Rights, but not otherwise.
-
-       2. Patent and trademark rights are not licensed under this
-          Public License.
-
-       3. To the extent possible, the Licensor waives any right to
-          collect royalties from You for the exercise of the Licensed
-          Rights, whether directly or through a collecting society
-          under any voluntary or waivable statutory or compulsory
-          licensing scheme. In all other cases the Licensor expressly
-          reserves any right to collect such royalties, including when
-          the Licensed Material is used other than for NonCommercial
-          purposes.
-
-Section 3 -- License Conditions.
-
-Your exercise of the Licensed Rights is expressly made subject to the
-following conditions.
-
-  a. Attribution.
-
-       1. If You Share the Licensed Material (including in modified
-          form), You must:
-
-            a. retain the following if it is supplied by the Licensor
-               with the Licensed Material:
-
-                 i. identification of the creator(s) of the Licensed
-                    Material and any others designated to receive
-                    attribution, in any reasonable manner requested by
-                    the Licensor (including by pseudonym if
-                    designated);
-
-                ii. a copyright notice;
-
-               iii. a notice that refers to this Public License;
-
-                iv. a notice that refers to the disclaimer of
-                    warranties;
-
-                 v. a URI or hyperlink to the Licensed Material to the
-                    extent reasonably practicable;
-
-            b. indicate if You modified the Licensed Material and
-               retain an indication of any previous modifications; and
-
-            c. indicate the Licensed Material is licensed under this
-               Public License, and include the text of, or the URI or
-               hyperlink to, this Public License.
-
-       2. You may satisfy the conditions in Section 3(a)(1) in any
-          reasonable manner based on the medium, means, and context in
-          which You Share the Licensed Material. For example, it may be
-          reasonable to satisfy the conditions by providing a URI or
-          hyperlink to a resource that includes the required
-          information.
-
-       3. If requested by the Licensor, You must remove any of the
-          information required by Section 3(a)(1)(A) to the extent
-          reasonably practicable.
-
-       4. If You Share Adapted Material You produce, the Adapter's
-          License You apply must not prevent recipients of the Adapted
-          Material from complying with this Public License.
-
-Section 4 -- Sui Generis Database Rights.
-
-Where the Licensed Rights include Sui Generis Database Rights that
-apply to Your use of the Licensed Material:
-
-  a. for the avoidance of doubt, Section 2(a)(1) grants You the right
-     to extract, reuse, reproduce, and Share all or a substantial
-     portion of the contents of the database for NonCommercial purposes
-     only;
-
-  b. if You include all or a substantial portion of the database
-     contents in a database in which You have Sui Generis Database
-     Rights, then the database in which You have Sui Generis Database
-     Rights (but not its individual contents) is Adapted Material; and
-
-  c. You must comply with the conditions in Section 3(a) if You Share
-     all or a substantial portion of the contents of the database.
-
-For the avoidance of doubt, this Section 4 supplements and does not
-replace Your obligations under this Public License where the Licensed
-Rights include other Copyright and Similar Rights.
-
-Section 5 -- Disclaimer of Warranties and Limitation of Liability.
-
-  a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE
-     EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS
-     AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF
-     ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,
-     IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,
-     WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR
-     PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,
-     ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT
-     KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT
-     ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.
-
-  b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE
-     TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,
-     NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,
-     INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,
-     COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR
-     USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN
-     ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR
-     DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR
-     IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.
-
-  c. The disclaimer of warranties and limitation of liability provided
-     above shall be interpreted in a manner that, to the extent
-     possible, most closely approximates an absolute disclaimer and
-     waiver of all liability.
-
-Section 6 -- Term and Termination.
-
-  a. This Public License applies for the term of the Copyright and
-     Similar Rights licensed here. However, if You fail to comply with
-     this Public License, then Your rights under this Public License
-     terminate automatically.
-
-  b. Where Your right to use the Licensed Material has terminated under
-     Section 6(a), it reinstates:
-
-       1. automatically as of the date the violation is cured, provided
-          it is cured within 30 days of Your discovery of the
-          violation; or
-
-       2. upon express reinstatement by the Licensor.
-
-     For the avoidance of doubt, this Section 6(b) does not affect any
-     right the Licensor may have to seek remedies for Your violations
-     of this Public License.
-
-  c. For the avoidance of doubt, the Licensor may also offer the
-     Licensed Material under separate terms or conditions or stop
-     distributing the Licensed Material at any time; however, doing so
-     will not terminate this Public License.
-
-  d. Sections 1, 5, 6, 7, and 8 survive termination of this Public
-     License.
-
-Section 7 -- Other Terms and Conditions.
-
-  a. The Licensor shall not be bound by any additional or different
-     terms or conditions communicated by You unless expressly agreed.
-
-  b. Any arrangements, understandings, or agreements regarding the
-     Licensed Material not stated herein are separate from and
-     independent of the terms and conditions of this Public License.
-
-Section 8 -- Interpretation.
-
-  a. For the avoidance of doubt, this Public License does not, and
-     shall not be interpreted to, reduce, limit, restrict, or impose
-     conditions on any use of the Licensed Material that could lawfully
-     be made without permission under this Public License.
-
-  b. To the extent possible, if any provision of this Public License is
-     deemed unenforceable, it shall be automatically reformed to the
-     minimum extent necessary to make it enforceable. If the provision
-     cannot be reformed, it shall be severed from this Public License
-     without affecting the enforceability of the remaining terms and
-     conditions.
-
-  c. No term or condition of this Public License will be waived and no
-     failure to comply consented to unless expressly agreed to by the
-     Licensor.
-
-  d. Nothing in this Public License constitutes or may be interpreted
-     as a limitation upon, or waiver of, any privileges and immunities
-     that apply to the Licensor or You, including from the legal
-     processes of any jurisdiction or authority.
-
-=======================================================================
-
-Creative Commons is not a party to its public
-licenses. Notwithstanding, Creative Commons may elect to apply one of
-its public licenses to material it publishes and in those instances
-will be considered the “Licensor.” The text of the Creative Commons
-public licenses is dedicated to the public domain under the CC0 Public
-Domain Dedication. Except for the limited purpose of indicating that
-material is shared under a Creative Commons public license or as
-otherwise permitted by the Creative Commons policies published at
-creativecommons.org/policies, Creative Commons does not authorize the
-use of the trademark "Creative Commons" or any other trademark or logo
-of Creative Commons without its prior written consent including,
-without limitation, in connection with any unauthorized modifications
-to any of its public licenses or any other arrangements,
-understandings, or agreements concerning use of licensed material. For
-the avoidance of doubt, this paragraph does not form part of the
-public licenses.
-
-Creative Commons may be contacted at creativecommons.org.
diff --git a/src/pl_bolts/models/self_supervised/moco/__init__.py b/src/pl_bolts/models/self_supervised/moco/__init__.py
deleted file mode 100644
index 98527ec..0000000
--- a/src/pl_bolts/models/self_supervised/moco/__init__.py
+++ /dev/null
@@ -1,8 +0,0 @@
-from pl_bolts.transforms.self_supervised.moco_transforms import (  # noqa: F401
-    MoCo2EvalCIFAR10Transforms,
-    MoCo2EvalImagenetTransforms,
-    MoCo2EvalSTL10Transforms,
-    MoCo2TrainCIFAR10Transforms,
-    MoCo2TrainImagenetTransforms,
-    MoCo2TrainSTL10Transforms,
-)
diff --git a/src/pl_bolts/models/self_supervised/moco/callbacks.py b/src/pl_bolts/models/self_supervised/moco/callbacks.py
deleted file mode 100644
index dfc4bb3..0000000
--- a/src/pl_bolts/models/self_supervised/moco/callbacks.py
+++ /dev/null
@@ -1,29 +0,0 @@
-import math
-
-from pytorch_lightning import Callback
-
-from pl_bolts.utils.stability import under_review
-
-
-@under_review()
-class MocoLRScheduler(Callback):
-    def __init__(self, initial_lr=0.03, use_cosine_scheduler=False, schedule=(120, 160), max_epochs=200) -> None:
-        super().__init__()
-        self.lr = initial_lr
-        self.use_cosine_scheduler = use_cosine_scheduler
-        self.schedule = schedule
-        self.max_epochs = max_epochs
-
-    def on_train_epoch_start(self, trainer, pl_module):
-        epoch = trainer.current_epoch
-        lr = self.lr
-
-        if self.use_cosine_scheduler:  # cosine lr schedule
-            lr *= 0.5 * (1.0 + math.cos(math.pi * epoch / self.max_epochs))
-        else:  # stepwise lr schedule
-            for milestone in self.schedule:
-                lr *= 0.1 if epoch >= milestone else 1.0
-
-        optimizer = trainer.optimizers[0]
-        for param_group in optimizer.param_groups:
-            param_group["lr"] = lr
diff --git a/src/pl_bolts/models/self_supervised/moco/moco2_module.py b/src/pl_bolts/models/self_supervised/moco/moco2_module.py
deleted file mode 100644
index 2c53461..0000000
--- a/src/pl_bolts/models/self_supervised/moco/moco2_module.py
+++ /dev/null
@@ -1,399 +0,0 @@
-# Original work is: Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
-# This implementation is: Copyright (c) PyTorch Lightning, Inc. and its affiliates. All Rights Reserved
-#
-# This implementation is licensed under Attribution-NonCommercial 4.0 International;
-# You may not use this file except in compliance with the License.
-#
-# You may obtain a copy of the License from the LICENSE file present in this folder.
-"""MoCo2.
-
-Adapted from https: //github.com/facebookresearch/moco.
-"""
-from argparse import ArgumentParser
-from typing import Union
-
-import torch
-from pytorch_lightning import LightningModule, Trainer
-from pytorch_lightning.strategies import DDPStrategy
-from torch import nn
-from torch.nn import functional as F  # noqa: N812
-
-from pl_bolts.metrics import mean, precision_at_k
-from pl_bolts.transforms.self_supervised.moco_transforms import (
-    MoCo2EvalCIFAR10Transforms,
-    MoCo2EvalImagenetTransforms,
-    MoCo2EvalSTL10Transforms,
-    MoCo2TrainCIFAR10Transforms,
-    MoCo2TrainImagenetTransforms,
-    MoCo2TrainSTL10Transforms,
-)
-from pl_bolts.utils import _TORCHVISION_AVAILABLE
-from pl_bolts.utils.stability import under_review
-from pl_bolts.utils.warnings import warn_missing_pkg
-
-if _TORCHVISION_AVAILABLE:
-    import torchvision
-else:  # pragma: no cover
-    warn_missing_pkg("torchvision")
-
-
-@under_review()
-class Moco_v2(LightningModule):  # noqa: N801
-    """PyTorch Lightning implementation of `Moco <https://arxiv.org/abs/2003.04297>`_
-
-    Paper authors: Xinlei Chen, Haoqi Fan, Ross Girshick, Kaiming He.
-
-    Code adapted from `facebookresearch/moco <https://github.com/facebookresearch/moco>`_ to Lightning by:
-
-        - `William Falcon <https://github.com/williamFalcon>`_
-
-    Example::
-
-        from pl_bolts.models.self_supervised import Moco_v2
-        model = Moco_v2()
-        trainer = Trainer()
-        trainer.fit(model)
-
-    CLI command::
-
-        # cifar10
-        python moco2_module.py --gpus 1
-
-        # imagenet
-        python moco2_module.py
-            --gpus 8
-            --dataset imagenet2012
-            --data_dir /path/to/imagenet/
-            --meta_dir /path/to/folder/with/meta.bin/
-            --batch_size 32
-    """
-
-    def __init__(
-        self,
-        base_encoder: Union[str, torch.nn.Module] = "resnet18",
-        emb_dim: int = 128,
-        num_negatives: int = 65536,
-        encoder_momentum: float = 0.999,
-        softmax_temperature: float = 0.07,
-        learning_rate: float = 0.03,
-        momentum: float = 0.9,
-        weight_decay: float = 1e-4,
-        data_dir: str = "./",
-        batch_size: int = 256,
-        use_mlp: bool = False,
-        num_workers: int = 8,
-        *args,
-        **kwargs
-    ) -> None:
-        """
-        Args:
-            base_encoder: torchvision model name or torch.nn.Module
-            emb_dim: feature dimension (default: 128)
-            num_negatives: queue size; number of negative keys (default: 65536)
-            encoder_momentum: moco momentum of updating key encoder (default: 0.999)
-            softmax_temperature: softmax temperature (default: 0.07)
-            learning_rate: the learning rate
-            momentum: optimizer momentum
-            weight_decay: optimizer weight decay
-            datamodule: the DataModule (train, val, test dataloaders)
-            data_dir: the directory to store data
-            batch_size: batch size
-            use_mlp: add an mlp to the encoders
-            num_workers: workers for the loaders
-        """
-
-        super().__init__()
-        self.save_hyperparameters()
-
-        # create the encoders
-        # num_classes is the output fc dimension
-        self.encoder_q, self.encoder_k = self.init_encoders(base_encoder)
-
-        if use_mlp:  # hack: brute-force replacement
-            dim_mlp = self.encoder_q.fc.weight.shape[1]
-            self.encoder_q.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc)
-            self.encoder_k.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc)
-
-        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):
-            param_k.data.copy_(param_q.data)  # initialize
-            param_k.requires_grad = False  # not update by gradient
-
-        # create the queue
-        self.register_buffer("queue", torch.randn(emb_dim, num_negatives))
-        self.queue = nn.functional.normalize(self.queue, dim=0)
-
-        self.register_buffer("queue_ptr", torch.zeros(1, dtype=torch.long))
-
-        # create the validation queue
-        self.register_buffer("val_queue", torch.randn(emb_dim, num_negatives))
-        self.val_queue = nn.functional.normalize(self.val_queue, dim=0)
-
-        self.register_buffer("val_queue_ptr", torch.zeros(1, dtype=torch.long))
-
-    def init_encoders(self, base_encoder):
-        """Override to add your own encoders."""
-
-        template_model = getattr(torchvision.models, base_encoder)
-        encoder_q = template_model(num_classes=self.hparams.emb_dim)
-        encoder_k = template_model(num_classes=self.hparams.emb_dim)
-
-        return encoder_q, encoder_k
-
-    @torch.no_grad()
-    def _momentum_update_key_encoder(self):
-        """Momentum update of the key encoder."""
-        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):
-            em = self.hparams.encoder_momentum
-            param_k.data = param_k.data * em + param_q.data * (1.0 - em)
-
-    @torch.no_grad()
-    def _dequeue_and_enqueue(self, keys, queue_ptr, queue):
-        # gather keys before updating queue
-        if self._use_ddp(self.trainer):
-            keys = concat_all_gather(keys)
-
-        batch_size = keys.shape[0]
-
-        ptr = int(queue_ptr)
-        assert self.hparams.num_negatives % batch_size == 0  # for simplicity
-
-        # replace the keys at ptr (dequeue and enqueue)
-        queue[:, ptr : ptr + batch_size] = keys.T
-        ptr = (ptr + batch_size) % self.hparams.num_negatives  # move pointer
-
-        queue_ptr[0] = ptr
-
-    @torch.no_grad()
-    def _batch_shuffle_ddp(self, x):  # pragma: no cover
-        """Batch shuffle, for making use of BatchNorm.
-
-        *** Only support DistributedDataParallel (DDP) model. ***
-        """
-        # gather from all gpus
-        batch_size_this = x.shape[0]
-        x_gather = concat_all_gather(x)
-        batch_size_all = x_gather.shape[0]
-
-        num_gpus = batch_size_all // batch_size_this
-
-        # random shuffle index
-        idx_shuffle = torch.randperm(batch_size_all).cuda()
-
-        # broadcast to all gpus
-        torch.distributed.broadcast(idx_shuffle, src=0)
-
-        # index for restoring
-        idx_unshuffle = torch.argsort(idx_shuffle)
-
-        # shuffled index for this gpu
-        gpu_idx = torch.distributed.get_rank()
-        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]
-
-        return x_gather[idx_this], idx_unshuffle
-
-    @torch.no_grad()
-    def _batch_unshuffle_ddp(self, x, idx_unshuffle):  # pragma: no cover
-        """Undo batch shuffle.
-
-        *** Only support DistributedDataParallel (DDP) model. ***
-        """
-        # gather from all gpus
-        batch_size_this = x.shape[0]
-        x_gather = concat_all_gather(x)
-        batch_size_all = x_gather.shape[0]
-
-        num_gpus = batch_size_all // batch_size_this
-
-        # restored index for this gpu
-        gpu_idx = torch.distributed.get_rank()
-        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]
-
-        return x_gather[idx_this]
-
-    def forward(self, img_q, img_k, queue):
-        """
-        Input:
-            im_q: a batch of query images
-            im_k: a batch of key images
-            queue: a queue from which to pick negative samples
-        Output:
-            logits, targets
-        """
-
-        # compute query features
-        q = self.encoder_q(img_q)  # queries: NxC
-        q = nn.functional.normalize(q, dim=1)
-
-        # compute key features
-        with torch.no_grad():  # no gradient to keys
-            # shuffle for making use of BN
-            if self._use_ddp(self.trainer):
-                img_k, idx_unshuffle = self._batch_shuffle_ddp(img_k)
-
-            k = self.encoder_k(img_k)  # keys: NxC
-            k = nn.functional.normalize(k, dim=1)
-
-            # undo shuffle
-            if self._use_ddp(self.trainer):
-                k = self._batch_unshuffle_ddp(k, idx_unshuffle)
-
-        # compute logits
-        # Einstein sum is more intuitive
-        # positive logits: Nx1
-        l_pos = torch.einsum("nc,nc->n", [q, k]).unsqueeze(-1)
-        # negative logits: NxK
-        l_neg = torch.einsum("nc,ck->nk", [q, queue.clone().detach()])
-
-        # logits: Nx(1+K)
-        logits = torch.cat([l_pos, l_neg], dim=1)
-
-        # apply temperature
-        logits /= self.hparams.softmax_temperature
-
-        # labels: positive key indicators
-        labels = torch.zeros(logits.shape[0], dtype=torch.long)
-        labels = labels.type_as(logits)
-
-        return logits, labels, k
-
-    def training_step(self, batch, batch_idx):
-        # in STL10 we pass in both lab+unl for online ft
-        if self.trainer.datamodule.name == "stl10":
-            # labeled_batch = batch[1]
-            unlabeled_batch = batch[0]
-            batch = unlabeled_batch
-
-        (img_1, img_2), _ = batch
-
-        self._momentum_update_key_encoder()  # update the key encoder
-        output, target, keys = self(img_q=img_1, img_k=img_2, queue=self.queue)
-        self._dequeue_and_enqueue(keys, queue=self.queue, queue_ptr=self.queue_ptr)  # dequeue and enqueue
-
-        loss = F.cross_entropy(output.float(), target.long())
-
-        acc1, acc5 = precision_at_k(output, target, top_k=(1, 5))
-
-        log = {"train_loss": loss, "train_acc1": acc1, "train_acc5": acc5}
-        self.log_dict(log)
-        return loss
-
-    def validation_step(self, batch, batch_idx):
-        # in STL10 we pass in both lab+unl for online ft
-        if self.trainer.datamodule.name == "stl10":
-            # labeled_batch = batch[1]
-            unlabeled_batch = batch[0]
-            batch = unlabeled_batch
-
-        (img_1, img_2), labels = batch
-
-        output, target, keys = self(img_q=img_1, img_k=img_2, queue=self.val_queue)
-        self._dequeue_and_enqueue(keys, queue=self.val_queue, queue_ptr=self.val_queue_ptr)  # dequeue and enqueue
-
-        loss = F.cross_entropy(output, target.long())
-
-        acc1, acc5 = precision_at_k(output, target, top_k=(1, 5))
-
-        return {"val_loss": loss, "val_acc1": acc1, "val_acc5": acc5}
-
-    def validation_epoch_end(self, outputs):
-        val_loss = mean(outputs, "val_loss")
-        val_acc1 = mean(outputs, "val_acc1")
-        val_acc5 = mean(outputs, "val_acc5")
-
-        log = {"val_loss": val_loss, "val_acc1": val_acc1, "val_acc5": val_acc5}
-        self.log_dict(log)
-
-    def configure_optimizers(self):
-        optimizer = torch.optim.SGD(
-            self.parameters(),
-            self.hparams.learning_rate,
-            momentum=self.hparams.momentum,
-            weight_decay=self.hparams.weight_decay,
-        )
-        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
-            optimizer,
-            self.trainer.max_epochs,
-        )
-        return [optimizer], [scheduler]
-
-    @staticmethod
-    def add_model_specific_args(parent_parser):
-        parser = ArgumentParser(parents=[parent_parser], add_help=False)
-        parser.add_argument("--base_encoder", type=str, default="resnet18")
-        parser.add_argument("--emb_dim", type=int, default=128)
-        parser.add_argument("--num_workers", type=int, default=8)
-        parser.add_argument("--num_negatives", type=int, default=65536)
-        parser.add_argument("--encoder_momentum", type=float, default=0.999)
-        parser.add_argument("--softmax_temperature", type=float, default=0.07)
-        parser.add_argument("--learning_rate", type=float, default=0.03)
-        parser.add_argument("--momentum", type=float, default=0.9)
-        parser.add_argument("--weight_decay", type=float, default=1e-4)
-        parser.add_argument("--data_dir", type=str, default="./")
-        parser.add_argument("--dataset", type=str, default="cifar10", choices=["cifar10", "imagenet2012", "stl10"])
-        parser.add_argument("--batch_size", type=int, default=256)
-        parser.add_argument("--use_mlp", action="store_true")
-        parser.add_argument("--meta_dir", default=".", type=str, help="path to meta.bin for imagenet")
-
-        return parser
-
-    @staticmethod
-    def _use_ddp(trainer: Trainer) -> bool:
-        return isinstance(trainer.strategy, DDPStrategy)
-
-
-# utils
-@torch.no_grad()
-@under_review()
-def concat_all_gather(tensor):
-    """Performs all_gather operation on the provided tensors.
-
-    *** Warning ***: torch.distributed.all_gather has no gradient.
-    """
-    tensors_gather = [torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())]
-    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)
-
-    return torch.cat(tensors_gather, dim=0)
-
-
-@under_review()
-def cli_main():
-    from pl_bolts.datamodules import CIFAR10DataModule, SSLImagenetDataModule, STL10DataModule
-
-    parser = ArgumentParser()
-
-    # trainer args
-    parser = Trainer.add_argparse_args(parser)
-
-    # model args
-    parser = Moco_v2.add_model_specific_args(parser)
-    args = parser.parse_args()
-
-    if args.dataset == "cifar10":
-        datamodule = CIFAR10DataModule.from_argparse_args(args)
-        datamodule.train_transforms = MoCo2TrainCIFAR10Transforms()
-        datamodule.val_transforms = MoCo2EvalCIFAR10Transforms()
-
-    elif args.dataset == "stl10":
-        datamodule = STL10DataModule.from_argparse_args(args)
-        datamodule.train_dataloader = datamodule.train_dataloader_mixed
-        datamodule.val_dataloader = datamodule.val_dataloader_mixed
-        datamodule.train_transforms = MoCo2TrainSTL10Transforms()
-        datamodule.val_transforms = MoCo2EvalSTL10Transforms()
-
-    elif args.dataset == "imagenet2012":
-        datamodule = SSLImagenetDataModule.from_argparse_args(args)
-        datamodule.train_transforms = MoCo2TrainImagenetTransforms()
-        datamodule.val_transforms = MoCo2EvalImagenetTransforms()
-
-    else:
-        # replace with your own dataset, otherwise CIFAR-10 will be used by default if `None` passed in
-        datamodule = None
-
-    model = Moco_v2(**args.__dict__)
-
-    trainer = Trainer.from_argparse_args(args)
-    trainer.fit(model, datamodule=datamodule)
-
-
-if __name__ == "__main__":
-    cli_main()
diff --git a/tests/models/self_supervised/test_models.py b/tests/models/self_supervised/test_models.py
index 0605b9c..d820976 100644
--- a/tests/models/self_supervised/test_models.py
+++ b/tests/models/self_supervised/test_models.py
@@ -3,11 +3,9 @@ import warnings
 import pytest
 import torch
 from pl_bolts.datamodules import CIFAR10DataModule
-from pl_bolts.models.self_supervised import AMDIM, BYOL, CPC_v2, Moco_v2, SimCLR, SimSiam, SwAV
+from pl_bolts.models.self_supervised import AMDIM, BYOL, CPC_v2, SimCLR, SimSiam, SwAV
 from pl_bolts.models.self_supervised.cpc import CPCEvalTransformsCIFAR10, CPCTrainTransformsCIFAR10
-from pl_bolts.models.self_supervised.moco.callbacks import MocoLRScheduler
 from pl_bolts.transforms.dataset_normalizations import cifar10_normalization
-from pl_bolts.transforms.self_supervised.moco_transforms import MoCo2EvalCIFAR10Transforms, MoCo2TrainCIFAR10Transforms
 from pl_bolts.transforms.self_supervised.simclr_transforms import SimCLREvalDataTransform, SimCLRTrainDataTransform
 from pl_bolts.transforms.self_supervised.swav_transforms import SwAVEvalDataTransform, SwAVTrainDataTransform
 from pl_bolts.utils import _IS_WINDOWS
@@ -73,17 +71,6 @@ def test_amdim(tmpdir, datadir):
     trainer.fit(model)
 
 
-@pytest.mark.skipif(_IS_WINDOWS, reason="numpy.core._exceptions._ArrayMemoryError...")  # todo
-def test_moco(tmpdir, datadir):
-    datamodule = CIFAR10DataModule(data_dir=datadir, num_workers=0, batch_size=2)
-    datamodule.train_transforms = MoCo2TrainCIFAR10Transforms()
-    datamodule.val_transforms = MoCo2EvalCIFAR10Transforms()
-
-    model = Moco_v2(data_dir=datadir, batch_size=2, online_ft=True)
-    trainer = Trainer(fast_dev_run=True, default_root_dir=tmpdir, callbacks=[MocoLRScheduler()])
-    trainer.fit(model, datamodule=datamodule)
-
-
 @pytest.mark.skipif(_IS_WINDOWS, reason="numpy.core._exceptions._ArrayMemoryError...")  # todo
 def test_simclr(tmpdir, datadir):
     datamodule = CIFAR10DataModule(data_dir=datadir, num_workers=0, batch_size=2)
diff --git a/tests/models/test_scripts.py b/tests/models/test_scripts.py
index 9cdad72..c679056 100644
--- a/tests/models/test_scripts.py
+++ b/tests/models/test_scripts.py
@@ -85,11 +85,6 @@ _ARG_WORKERS_0 = " --num_workers=0"
                 pytest.mark.xfail(reason="failing for GPU as some is on CPU other on GPU"),
             ],
         ),
-        pytest.param(
-            "models.self_supervised.moco.moco2_module",
-            _DEFAULT_ARGS + _ARG_WORKERS_0 + _ARG_GPUS,
-            marks=pytest.mark.skipif(**_MARK_REQUIRE_GPU),
-        ),
         pytest.param(
             "models.self_supervised.simclr.simclr_module",
             _DEFAULT_ARGS + _ARG_WORKERS_0 + _ARG_GPUS + " --online_ft --fp32",
diff --git a/tests/transforms/test_transforms.py b/tests/transforms/test_transforms.py
index a2082a1..4023199 100644
--- a/tests/transforms/test_transforms.py
+++ b/tests/transforms/test_transforms.py
@@ -27,14 +27,6 @@ from pl_bolts.transforms.self_supervised.cpc_transforms import (
     CPCTrainTransformsImageNet128,
     CPCTrainTransformsSTL10,
 )
-from pl_bolts.transforms.self_supervised.moco_transforms import (
-    MoCo2EvalCIFAR10Transforms,
-    MoCo2EvalImagenetTransforms,
-    MoCo2EvalSTL10Transforms,
-    MoCo2TrainCIFAR10Transforms,
-    MoCo2TrainImagenetTransforms,
-    MoCo2TrainSTL10Transforms,
-)
 from pl_bolts.transforms.self_supervised.simclr_transforms import SimCLREvalDataTransform, SimCLRTrainDataTransform
 
 
-- 
2.40.1

