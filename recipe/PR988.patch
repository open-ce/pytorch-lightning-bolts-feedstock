diff --git a/pl_bolts/callbacks/data_monitor.py b/pl_bolts/callbacks/data_monitor.py
index 9653796..b3bdb78 100644
--- a/pl_bolts/callbacks/data_monitor.py
+++ b/pl_bolts/callbacks/data_monitor.py
@@ -3,9 +3,9 @@ from typing import Any, Dict, List, Optional, Sequence, Union
 import numpy as np
 import torch
 from pytorch_lightning import Callback, LightningModule, Trainer
-from pytorch_lightning.loggers import LightningLoggerBase, TensorBoardLogger, WandbLogger
+from pytorch_lightning.loggers import Logger, TensorBoardLogger, WandbLogger
 from pytorch_lightning.utilities import rank_zero_warn
-from pytorch_lightning.utilities.apply_func import apply_to_collection
+from lightning_utilities.core.apply_func import apply_to_collection
 from torch import Tensor, nn
 from torch.nn import Module
 from torch.utils.hooks import RemovableHandle
@@ -97,7 +97,7 @@ class DataMonitorBase(Callback):
 
             logger.experiment.log(data={name: wandb.Histogram(tensor)}, commit=False)
 
-    def _is_logger_available(self, logger: LightningLoggerBase) -> bool:
+    def _is_logger_available(self, logger: Logger) -> bool:
         available = True
         if not logger:
             rank_zero_warn("Cannot log histograms because Trainer has no logger.")
diff --git a/pl_bolts/callbacks/verification/batch_gradient.py b/pl_bolts/callbacks/verification/batch_gradient.py
index 6da56cc..884e76b 100644
--- a/pl_bolts/callbacks/verification/batch_gradient.py
+++ b/pl_bolts/callbacks/verification/batch_gradient.py
@@ -5,7 +5,7 @@ from typing import Any, Callable, Iterable, List, Optional, Type
 import torch
 import torch.nn as nn
 from pytorch_lightning import LightningModule, Trainer
-from pytorch_lightning.utilities.apply_func import apply_to_collection
+from lightning_utilities.core.apply_func import apply_to_collection
 from pytorch_lightning.utilities.exceptions import MisconfigurationException
 from torch import Tensor
 
diff --git a/pl_bolts/datamodules/async_dataloader.py b/pl_bolts/datamodules/async_dataloader.py
index 93ddc84..0767ad4 100644
--- a/pl_bolts/datamodules/async_dataloader.py
+++ b/pl_bolts/datamodules/async_dataloader.py
@@ -6,7 +6,6 @@ from typing import Any, Optional, Union
 
 import torch
 from torch import Tensor
-from torch._six import string_classes
 from torch.utils.data import DataLoader, Dataset
 
 from pl_bolts.utils.stability import under_review
@@ -85,7 +84,7 @@ class AsynchronousLoader:
             return {key: self.load_instance(sample[key]) for key in sample}
         elif isinstance(sample, tuple) and hasattr(sample, "_fields"):  # namedtuple
             return elem_type(*(self.load_instance(d) for d in sample))
-        elif isinstance(sample, container_abcs.Sequence) and not isinstance(sample, string_classes):
+        elif isinstance(sample, container_abcs.Sequence) and not isinstance(sample, str):
             return [self.load_instance(s) for s in sample]
         else:
             return sample
diff --git a/requirements.txt b/requirements.txt
index 64a6696..317e00c 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,3 +1,4 @@
-pytorch-lightning>=1.7.0
-lightning-utilities>=0.3.0, !=0.4.0  # this is needed for PL 1.7
-torchvision>=0.10.0
+numpy<=1.24.0 # todo: seeing some compatibility issues
+pytorch-lightning>=1.9.4
+lightning-utilities==0.7.1
+torchvision>=0.13  # todo: move to topic related extras
diff --git a/requirements/models.txt b/requirements/models.txt
index b7a548e..5cb2f80 100644
--- a/requirements/models.txt
+++ b/requirements/models.txt
@@ -1,8 +1,8 @@
-torchvision>=0.10.*
+torchvision>=0.13
 scikit-learn>=1.0.2
 Pillow
 opencv-python-headless
-gym[atari]>=0.17.2, <0.20.0  # needed for RL
+gym[atari]>=0.17.2, <0.27.0 # needed for RL
 atari_py==0.2.*
 box2d-py==2.3.*
 opencv-python>=4.5.5.62
diff --git a/tests/callbacks/test_ort.py b/tests/callbacks/test_ort.py
index 38897b1..8c8af62 100644
--- a/tests/callbacks/test_ort.py
+++ b/tests/callbacks/test_ort.py
@@ -14,7 +14,7 @@
 
 import pytest
 from pytorch_lightning import Callback, Trainer
-from pytorch_lightning.core.lightning import LightningModule
+from pytorch_lightning import LightningModule
 from pytorch_lightning.utilities.exceptions import MisconfigurationException
 
 from pl_bolts.callbacks import ORTCallback
diff --git a/tests/callbacks/test_sparseml.py b/tests/callbacks/test_sparseml.py
index 006416d..181afee 100644
--- a/tests/callbacks/test_sparseml.py
+++ b/tests/callbacks/test_sparseml.py
@@ -17,7 +17,7 @@ from pathlib import Path
 import pytest
 import torch
 from pytorch_lightning import Callback, Trainer
-from pytorch_lightning.core.lightning import LightningModule
+from pytorch_lightning import LightningModule
 from pytorch_lightning.utilities.exceptions import MisconfigurationException
 
 from pl_bolts.callbacks import SparseMLCallback
diff --git a/tests/callbacks/test_variational_callbacks.py b/tests/callbacks/test_variational_callbacks.py
index 7576676..c0c7fb7 100644
--- a/tests/callbacks/test_variational_callbacks.py
+++ b/tests/callbacks/test_variational_callbacks.py
@@ -1,4 +1,4 @@
-from pytorch_lightning.loggers.base import DummyLogger
+from pytorch_lightning.loggers.logger import DummyLogger
 
 from pl_bolts.callbacks import LatentDimInterpolator
 from pl_bolts.models.gans import GAN
diff --git a/tests/conftest.py b/tests/conftest.py
index 6b63d39..984ab22 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -5,8 +5,8 @@ from pathlib import Path
 
 import pytest
 import torch
-from pytorch_lightning.trainer.connectors.signal_connector import SignalConnector
-from pytorch_lightning.utilities.imports import _IS_WINDOWS
+from pytorch_lightning.trainer.connectors.signal_connector import _SignalConnector
+from lightning_fabric.utilities.imports import _IS_WINDOWS
 
 from pl_bolts.utils import _TORCHVISION_AVAILABLE, _TORCHVISION_LESS_THAN_0_13
 from pl_bolts.utils.stability import UnderReviewWarning
@@ -81,7 +81,7 @@ def restore_signal_handlers():
 
     This is a safety net for tests that don't run Trainer's teardown.
     """
-    valid_signals = SignalConnector._valid_signals()
+    valid_signals = _SignalConnector._valid_signals()
     if not _IS_WINDOWS:
         # SIGKILL and SIGSTOP are not allowed to be modified by the user
         valid_signals -= {signal.SIGKILL, signal.SIGSTOP}
